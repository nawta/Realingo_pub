# 開発ログ - 2025年6月30日

## Heron-NVILA-Lite-2Bモデルのビジョン関連ファイル調査

### 調査概要
Heron-NVILA-Lite-2Bモデルのビジョン関連ファイル構造とllama.cppでの使用方法について調査を実施。

### モデル構造
Heron-NVILA-Lite-2B（https://huggingface.co/turing-motors/Heron-NVILA-Lite-2B）は以下の構造を持つ：

#### 主要コンポーネント
1. **言語モデル（llm/）**
   - Qwen2.5-1.5B-Instructベース
   - 隠れ層サイズ: 1536
   - 層数: 28
   - アテンションヘッド数: 12

2. **ビジョンタワー（vision_tower/）**
   - SiglipVisionModelベース
   - ファイル:
     - config.json (644 Bytes)
     - model.safetensors (827 MB) - 視覚エンコーダの重み
     - preprocessor_config.json (394 Bytes)
   - 画像サイズ: 448x448
   - 層数: 27
   - アテンションヘッド数: 16

3. **マルチモーダルプロジェクター（mm_projector/）**
   - タイプ: mlp_downsample_2x2_fix
   - ファイル:
     - config.json (307 Bytes)
     - model.safetensors (18.9 MB) - プロジェクタの重み
   - 役割: ビジョンエンコーダ（2048次元）から言語モデル（1536次元）への変換

### llama.cppでのビジョンモデルサポート

#### 1. libmtmdライブラリ
- llama.cppはmultimodal support用に`libmtmd`ライブラリを提供
- 旧来の`llava.cpp`を置き換える新しい統一インターフェース
- 画像・音声入力をサポート

#### 2. mmproj（Multimodal Projector）ファイル
- ビジョンモデルを実行するには2つのGGUFファイルが必要：
  1. 言語モデルファイル（.gguf）
  2. マルチモーダルプロジェクタファイル（mmproj.gguf）

#### 3. 使用方法
```bash
# 基本的な使い方
llama-mtmd-cli -m model.gguf --mmproj mmproj.gguf

# サーバーモードでの使用
llama-server -m model.gguf --mmproj mmproj.gguf

# GPU無効化オプション
llama-server -m model.gguf --mmproj mmproj.gguf --no-mmproj-offload
```

### Heron-NVILA-Lite-2Bの変換手順

1. **モデルのダウンロード**
   - Hugging Faceから完全なモデルをダウンロード
   - vision_tower/とmm_projector/のファイルが必要

2. **GGUF形式への変換**
   - 言語モデル部分: `convert_hf_to_gguf.py`を使用
   - プロジェクタ部分: `--mmproj`フラグを付けて変換
   ```bash
   python convert_hf_to_gguf.py --mmproj path/to/heron-nvila-lite-2b
   ```

3. **量子化（オプション）**
   - Q4_K_M形式などへの量子化が可能
   - mmproj部分も個別に量子化可能

### 実装上の注意点

1. **アーキテクチャの互換性**
   - Heron-NVILAは独自のVILAアーキテクチャを使用
   - 標準的なLLaVAやGemmaとは異なるため、専用の変換スクリプトが必要な可能性

2. **プロジェクタの実装**
   - mlp_downsample_2x2_fixタイプは2x2のダウンサンプリングを行うMLP
   - 視覚特徴量を言語モデルの入力空間に投影

3. **画像前処理**
   - 448x448ピクセルの画像サイズ
   - SIGLIPベースの前処理が必要

### 今後の作業
1. Heron-NVILA用の変換スクリプトの確認・作成
2. mmproj部分の正しい抽出方法の調査
3. 実際の推論テストの実施

## llava API統合実装

### LlavaIntegration.swift作成
- llama.cppのllava API統合ガイド
- 画像前処理機能（リサイズ、RGB変換）
- モデル固有のプロンプトテンプレート
- Gemma/Heron用の設定構造体

### VLMManager.swift更新
- HeronモデルのプロジェクションモデルURL設定
- requiresVisionTowerプロパティ追加（HeronはSIGLIPビジョンタワーが必要）

### LlamaContext.swift更新
- モデル固有の画像エンコーディング実装
- Gemma: 336x336画像、576パッチ
- Heron: 448x448画像、256パッチ（2x2ダウンサンプリング後）
- LlavaImageProcessorとの統合準備

### llava API統合のための実装詳細

#### 必要なC API（llama.xcframeworkに追加が必要）
```c
struct llava_image_embed {
    void * data;
    int width;
    int height;
    int n_channels;
};

struct llava_image_embed * llava_image_embed_make_from_data(
    const void * image_data,
    int width,
    int height,
    int channels,
    struct llama_context * ctx_llama,
    struct clip_ctx * ctx_clip
);

bool llava_eval_image_embed(
    struct llama_context * ctx_llama,
    const struct llava_image_embed * embed,
    int n_batch,
    int * n_past
);

void llava_image_embed_free(struct llava_image_embed * embed);
```

#### 統合手順
1. llama.xcframeworkにllava/clip APIを含める
2. ブリッジングヘッダーでllava.hをインポート
3. LlavaImageProcessorで実際のAPI呼び出しを実装
4. 各モデル（Gemma/Heron）固有の画像処理を適用

## 他アプリからの画像共有、レミニセンスモード、みんなの写真モードの実装

### 実装概要
仕様書に記載されている3つの主要機能を実装：
1. 他アプリから画像を受け取る機能（Share Extension）
2. レミニセンスモードの確認と改善
3. みんなの写真モード（コミュニティ写真）の実装

### 1. Share Extension実装
#### ShareViewController.swift
- iOS標準のShare Extensionを実装
- 写真アプリなどから画像を受け取る
- App Groupsを使用して共有ストレージに画像を保存
- メインアプリ起動時に処理

#### SharedImageHandler.swift
- Share Extensionから受け取った画像を処理
- 共有画像の読み込みと管理
- SharedImageProcessingViewで問題生成UIを提供

### 2. Firebase Storage統合
#### FirebaseStorageService.swift
- Firebase Storageへの画像アップロード機能
- コミュニティ写真の取得（みんなの写真モード用）
- 公開/非公開設定のサポート
- NSFWチェック用のメタデータ保存

#### PhotoUploadButton.swift
- 各問題画面に設置する写真アップロードボタン
- 公開/非公開を選択してアップロード
- アップロード進捗とエラー処理

### 3. みんなの写真モード実装
#### CommunityPhotosView.swift
- コミュニティで共有された写真の一覧表示
- ページネーション対応
- 写真選択から問題生成までのフロー
- NSFWチェック済みの写真のみ表示

### 4. UI更新
#### MainMenuView.swift更新
- みんなの写真モードへのナビゲーション追加
- 共有画像がある場合の自動遷移処理
- NavigationLinkを使用した画面遷移

#### LocalizationHelper.swift更新
- 新機能用のローカライゼーション追加
- 日本語、英語、フィンランド語対応

### 5. データモデル更新
#### Models.swift
- ExtendedQuizにcommunityPhotoIDフィールド追加
- コミュニティ写真を使用した問題の追跡

### 技術的詳細
- **App Groups**: group.com.realingo.shared
- **Firebase Storage バケット**: gs://realingo-e7a54.firebasestorage.app
- **画像形式**: JPEG（品質80%）
- **NSFWチェック**: Cloud Run Functions（将来実装予定）

### 今後の作業
1. Xcodeプロジェクトへの Share Extension ターゲット追加
2. App Groups の設定（Capabilities）
3. Firebase Storage パッケージの追加
4. Info.plist の NSExtension 設定
5. Cloud Run Functions でのNSFWチェック実装

## VLM機能の本実装

### 実施内容
1. **ContentView.swiftのQuiz/ExtendedQuiz変換エラーを修正**
   - PhotoUploadButtonコンポーネントがExtendedQuiz型を期待していたため、Quiz型からの変換ヘルパー関数を追加
   - quizToExtendedQuiz()関数を実装し、PhotoUploadButtonへ渡す前に変換するよう修正

2. **VLMダミー実装から本実装への移行**
   - LibLlama.swiftを完全に書き直し、llama.cppのC APIを使用する本格的な実装に変更
   - LlamaContextに以下の機能を実装:
     - LLaVA（Vision Language Model）サポート
     - CLIPモデルの読み込みと画像エンコーディング
     - generate_with_image()メソッドによる画像からのテキスト生成

3. **C/Swiftブリッジング設定**
   - realingo_v3-Bridging-Header.hを作成し、llama.h、llava.h、clip.hをインポート
   - realingo_v3.xcconfigでブリッジングヘッダーとリンク設定を有効化

4. **VLMサービスの更新**
   - VLMService.swiftを更新し、CLIPモデルのパスも管理するように変更
   - VLMの使用可能性チェックでCLIPモデルの存在も確認するよう修正
   - 不足していたメソッド（generateProblemFromImageURL、generateProblemFromImageData、generateImageDescription、evaluateAnswer）を実装

5. **VLMモデル定義の追加**
   - VLMManager.swiftにLLaVAモデル（v1.5とv1.6）の定義を追加
   - 各モデルのダウンロードURLとCLIPプロジェクションモデルのURLを設定
   - VLMModels.swiftにCLIPモデルのURL/ファイル名プロパティを追加

### 技術的詳細
- llama.xcframeworkには既にllava.hとclip.hが含まれていることを確認
- LlamaContextはActorとして実装し、スレッドセーフティを確保
- VLM使用時は低温度（0.1）を設定して、より正確な画像説明を生成

### 注意事項
- VLMを使用するには、LLaVAモデル本体とCLIPプロジェクションモデルの両方が必要
- モデルファイルは大きいため（3.8GB〜7.1GB）、ダウンロードに時間がかかる可能性がある
- ブリッジングヘッダーの設定により、C APIへの直接アクセスが可能になった

## レミニセンスモードの테스트/더미 데이터 필터링 구현

### 문제 상황
사용자가 레미니센스 모드에서 이상한/더미 데이터가 표시되는 문제를 보고함.
테스트 데이터나 개발용 더미 데이터가 실제 문제 목록에 섞여 보이는 상황.

### 조사 결과
1. **ReminiscenceManager.swift**: 테스트 데이터 생성 로직 없음
2. **DataPersistenceManager.swift**: 데이터 조회 시 필터링 없음
3. **테스트 파일들**: 격리된 테스트 데이터만 포함, 실제 DB에 영향 없음
4. **Firestore 쿼리**: participantID만으로 필터링, 테스트 데이터 구분 안됨

### 해결 방안 구현
DataPersistenceManager.swift에 포괄적인 테스트/더미 데이터 필터링 기능 추가:

#### 1. getReminiscenceQuizzes() 메서드 개선
- `isTestOrDummyData(ReminiscenceQuiz)` 헬퍼 함수 추가
- 조회된 각 문제에 대해 테스트 데이터 여부 검사
- 테스트 데이터는 nil 반환하여 목록에서 제외

#### 2. fetchQuizzes() 메서드 개선  
- `isTestOrDummyDataExtended(ExtendedQuiz)` 헬퍼 함수 추가
- 일반 문제 조회에서도 테스트 데이터 필터링

#### 3. fetchUserLogs() 메서드 개선
- `isTestOrDummyDataLog(ExtendedProblemLog)` 헬퍼 함수 추가
- 사용자 로그에서도 테스트 데이터 제거

#### 4. 필터링 조건
**ID 패턴 필터링:**
- "test", "dummy", "sample", "mock", "debug", "dev" 포함 (대소문자 무관)
- ID, participantID, 질문문, 생성자 정보에서 확인

**특정 테스트 ID 필터링:**
- "user-123", "participant-123", "test-user", "test-participant" 등
- 개발/테스트용으로 자주 사용되는 ID 패턴

**품질 기반 필터링:**
- 10자 미만의 비정상적으로 짧은 질문문
- 빈 답안 배열 (ReminiscenceQuiz)
- 2자 미만의 비정상적으로 짧은 답안 (ExtendedQuiz)

**질문문 내용 필터링:**
- "Test", "테스트", "dummy", "sample"로 시작하는 질문문

### 기술적 구현 내용
```swift
// 예시: ReminiscenceQuiz 필터링 로직
private func isTestOrDummyData(_ quiz: ReminiscenceQuiz) -> Bool {
    let testPatterns = ["test", "dummy", "sample", "mock", "debug", "dev"]
    
    for pattern in testPatterns {
        if quiz.id.contains(pattern) ||
           quiz.participantID.contains(pattern) ||
           quiz.questionText.contains(pattern) {
            return true
        }
    }
    
    // 추가 품질 검사...
    return false
}
```

### 결과 및 효과
1. **사용자 경험 개선**: 정상적인 레미니센스 문제만 표시
2. **데이터 품질 향상**: 모든 데이터 조회에서 일관된 필터링
3. **개발 편의성 유지**: 테스트 데이터는 개발 환경에서만 사용 가능
4. **디버깅 지원**: 필터링된 데이터는 콘솔에 로그 출력

### 커밋 정보
- 커밋 해시: 09c126d
- 수정 파일: realingo_v3/DataPersistenceManager.swift
- 변경 사항: +164줄 추가, -3줄 삭제

### 향후 고려사항
1. 프로덕션 환경에서의 필터링 성능 모니터링
2. 새로운 테스트 패턴 발견 시 필터링 조건 확장
3. 관리자용 테스트 데이터 보기 기능 (필요 시)